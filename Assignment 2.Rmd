##Introduction
The App Store is a digital distribution platform, developed and maintained by Apple Inc., for mobile apps on its iOS operating system. The App Store was opened on July 10, 2008, with an initial 500 applications available.   
The data consists of variables: ID, Name, Average User Rating, User Rating Count, Price, Age Rating, Size, Developer, Languages in which the app is available, Genre along with the Primary Genre of the app, Original & Current Version Release Date.  
 Initially, the data had many missing values and also a few apps were repeated. Data cleaning was done and missing values were imputed.  
 
##Problem Statements:
* To create a Popularity Index and rank the apps accordingly.  
* To find a free substitute for a paid app.  
* To rank the genres as per their popularity in 17+ age group.  

##Newly Added Variables:
* lan_count: The number of languages in which each app is available were calculated.
* diff_of_dates: The number of days between the current version and original release dates were calculated.



```{r ,message= FALSE,warning= FALSE }
library(readxl)
library(readr)
AppStore <- read_csv("C:/Users/keerti/Desktop/MSc 2/data mining/Assignment2/AppStore.csv", 
    col_types = cols(`Age Rating` = col_number(), 
        `Average User Rating` = col_number(), 
        Price = col_number(), Size = col_number(), 
        `User Rating Count` = col_number()))
data=AppStore
data=as.data.frame(data)
x=sum(is.na(data))
length(which(is.na(data)==TRUE))
y=nrow(data)*ncol(data)
#visualization of missing data
library(VIM)
mice_plot <- aggr(data, col=c('navyblue','yellow'),
                  numbers=TRUE, sortVars=FALSE,
                  labels=c("ID","Name","AUR","URC","Price","Developer","AR","Languages","Size","PG","Genres","RD","UVD"), cex.axis=0.9,
                  gap=3, ylab=c("Missing data","Pattern"),prop=FALSE,las=2)
```

```{r,results= FALSE,message= FALSE,warning=FALSE}
library(missMDA)
data=AppStore
data_co=data[,c(3,4,5,7,9)]   #continuous data
data_co=as.data.frame(data_co)  
nb=estim_ncpPCA(data_co,method.cv="Kfold",nbsim=50,scale = TRUE)
res.comp=imputePCA(data_co,ncp=nb$ncp,scale = TRUE)
imp=cbind.data.frame(res.comp$completeObs,data$Developer,data$Languages,data$Genres)
library(FactoMineR)
res.pca=PCA(res.comp$completeObs,graph=FALSE)
names(res.pca)
data1=as.data.frame(res.comp$completeObs)
```

```{r}
library(moments)
c(skewness(data1$Price),skewness(na.omit(AppStore$Price)))
c(kurtosis(data1$Price),kurtosis(na.omit(AppStore$Price)))

```
##After imputing missing data, the Average User Rating which had continuous values, was approximated. 
```{r New_unique,echo=FALSE,warning= FALSE,message=FALSE}
imp <- read_csv("C:/Users/keerti/Desktop/MSc 2/data mining/Assignment2/imp.csv")
data=as.data.frame(imp)
lan_count=table(as.matrix(data[,8]))
v=strsplit(data[,9],split = ",")
c1=0
con=c()
for(i in 1:nrow(data))
{
  con[i]=length(v[[i]])
}
a=cbind(data[,8],"con"=con)
imp_count=transform(data,"lan_count"=con)

imputed <- read_csv("C:/Users/keerti/Desktop/MSc 2/data mining/Assignment2/imputed.csv")
f1=duplicated(imputed[,2])
im=imputed[!duplicated(imputed[,2]),]
im=im[,-1]
sum(is.na(im))
```

##Question 1)  
###The **Technique for Order of Preference by Similarity to Ideal Solution** (TOPSIS) is a multi-criteria decision analysis method, which was originally developed by Ching-Lai Hwang and Yoon in 1981  with further developments by Yoon in 1987, and Hwang, Lai and Liu in 1993. It is a method of compensatory aggregation that compares a set of alternatives by identifying weights for each criterion, normalizing scores for each criterion and calculating the geometric distance between each alternative and the ideal alternative, which is the best score in each criterion. An assumption of TOPSIS is that the criteria are monotonically increasing or decreasing. Normalization is usually required as the parameters or criteria are often of incongruous dimensions in multi-criteria problems.  

```{r,warning=FALSE,message=FALSE}
imp_con=as.matrix(imputed[,c(4:6,8,15)])
library(topsis)
w=c(1,3,2,1,3)
d=c("+","+","-","+","+")
t=topsis(imp_con,w,d)
s=t[order(t$rank),]
na=imputed$Name[s$alt.row]
de=imputed$Developer[s$alt.row]
pr=imputed$Price[s$alt.row]
ge=imputed$Genres[s$alt.row]
lc=imputed$lan_count[s$alt.row]
pg=imputed$Primary.Genre[s$alt.row]
pop_app=cbind(na,de,pr,ge,lc,pg)
pop_app[1:6,1]
```
##Question 2)
```{r,echo=TRUE,message=FALSE,warning=FALSE}
free=subset(imputed,imputed$Price==0.00)
free=free[,-1]
paid=subset(imputed,imputed$Price!=0.00)
paid=paid[,-1]

length(unique(imputed$ID)) #to check repeated observations

paid_app <- read_csv("C:/Users/keerti/Desktop/MSc 2/data mining/Assignment2/paid_app.csv")
free_app <- read_csv("C:/Users/keerti/Desktop/MSc 2/data mining/Assignment2/free_app.csv")
mp=as.matrix(paid_app[,c(4,5,6,7,8,15)])
mf=as.matrix(free_app[,c(4,5,6,7,8,15)])
library(rdist)
library(pdist)
d1=pdist(mp,mf)
d2=as.matrix(d1)

row_min=apply(d2,1,which.min) #to get min distance from each observation
sim_name=as.data.frame(free_app[row_min,3]) #free apps similar to paid apps
sim_apps=cbind(paid_app$Name,sim_name) #similar apps
```
```{r best_sim,message=FALSE}
min_dis_mat=apply(d2,1,min)
min_dis=min(min_dis_mat)
max_dis=max(min_dis_mat)
so_min_dis_mat=sort(min_dis_mat) 
head(so_min_dis_mat) 
tail(so_min_dis_mat)
row=which(min_dis_mat<=50)
d3=data.frame(d2[row,])  ##rows of Paid data for which min_dis<=50 
r_mi=apply(d3,1,which.min)
best_sim_name=as.data.frame(free_app[r_mi,3])
best_sim_app=cbind(paid_app[row,3],best_sim_name)
```
##Question 3)
```{r,message=FALSE,warning=FALSE}
age=subset(imputed,imputed$Age.Rating>=17)
age17 <- read_csv("C:/Users/keerti/Desktop/MSc 2/data mining/Assignment2/age17.csv")
age17_con=as.matrix(age17[,c(5:7,9,16)])
library(topsis)
w1=c(1,3,2,1,3)
d1=c("+","+","-","+","+")
t1=topsis(age17_con,w1,d1)
s1=t1[order(t1$rank),]
gen_age=age17$Genres[s1$alt.row]
sc=s1[,2]
ap=age17$Name[s1$alt.row]
gen_str=strsplit(gen_age,",")
gen_count=c()
for(i in 1:nrow(age17))
{
  gen_count[i]=length(gen_str[[i]])
}
age_rank=cbind(ap,sc,gen_age,gen_count)
##rank the genres using "TOPSIS" and found score.
#assigned the weights to genres in decreasing order (i.e. highest weight to primry genre and same weights for all other genres.)
#Took weighted mean for each Genre and found most popular genre by considering maximum weighted mean.
age_rank <- read_csv("C:/Users/keerti/Desktop/MSc 2/data mining/Assignment2/age_rank.csv", 
    col_types = cols(gen_count = col_number(), 
        sc = col_number()))
age_rank=as.data.frame(age_rank)
n=age_rank$gen_count #length of genres for each app

nr=661 #row length

hw=matrix(0,nrow=nr,ncol=max(n))
for(i in 1:nr)
{
  hw[i,]=c(0.7,rep(0.5,(n[i]-1)),rep(0,4-n[i])) #0.7 for primary & 0.5 for secondary
}
hw[1:5,]

hsc=hw*age_rank$sc #applying horizontal wts to scores

#sg is a csv file in which the Genres column was converted from text to column n Excel and
# NAs replaced with 0
#View(sg) 
sg <- read_csv("C:/Users/keerti/Desktop/MSc 2/data mining/Assignment2/sg.csv",col_names = FALSE) 
    
sg=as.data.frame(sg[,-1]) #to remove the row numbers
nc=unique(c(unique(sg[,1]),unique(sg[,2]),unique(sg[,3]),unique(sg[,4])))
nc=nc[-31] #to remove 0

gnames <- read_csv("C:/Users/keerti/Desktop/MSc 2/data mining/Assignment2/gnames.csv")
gnames=as.data.frame(gnames[,-1]) #to remove row numbers 

mm=list()
for(k in 1:nrow(gnames))
{
  ga=matrix(nrow=nrow(sg),ncol=ncol(sg))
  for(i in 1:nrow(sg))
  {
    for(j in 1:ncol(sg))
    {
      ga[i,j]=ifelse(sg[i,j]==gnames[k,1],1,0)
    }
  }
  mm[[k]]=ga
}

msc=list()
for(i in 1:length(mm))
{
  msc[[i]]=hsc*mm[[i]]
}

nm=sm=me=c()
for(k in 1:length(mm))
{
  nm[k]=length(which(rowSums(msc[[k]])>0,arr.ind = TRUE))
  sm[k]=sum(msc[[k]])
  me[k]=sm[k]/nm[k]
}
p=cbind(nc,me)
p1=p[order(p[,2],decreasing = TRUE),]
head(p1)

```


